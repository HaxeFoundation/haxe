variables:
  - group: variables-haxe
  - name: AZURE_PIPELINES_REPO_URL
    value: $(Build.Repository.Uri)
  - name: AZURE_PIPELINES_BRANCH
    value: $(Build.SourceBranchName)

stages:
  - stage: StageTest
    jobs:
      - template: extra/azure-pipelines/build-linux.yml
        parameters:
          name: BuildLinux

      - template: extra/azure-pipelines/build-mac.yml
        parameters:
          name: BuildMac

      - template: extra/azure-pipelines/build-windows.yml
        parameters:
          name: BuildWin64
          arch: '64'

      - template: extra/azure-pipelines/build-windows.yml
        parameters:
          name: BuildWin32
          arch: '32'

      - job: TestLinux
        dependsOn: BuildLinux
        pool:
          vmImage: 'ubuntu-16.04'
        strategy:
          matrix:
            macro:
              TEST: macro
            neko:
              TEST: neko
            hl:
              TEST: hl
              APT_PACKAGES: cmake ninja-build
            cpp:
              TEST: cpp
              HXCPP_COMPILE_CACHE: ~/hxcache
              APT_PACKAGES: gcc-multilib g++-multilib
            java:
              TEST: java,jvm
            cs:
              TEST: cs
            js:
              TEST: js
              SAUCE: 1
              SAUCE_TUNNEL_ID: $(Agent.JobName)
              SAUCE_BUILD: $(Build.BuildNumber)
            php:
              TEST: php
            flash:
              TEST: flash9,as3
              APT_PACKAGES: libglib2.0 libfreetype6 xvfb
              DISPLAY: ':99.0'
              AUDIODEV: 'null'
            python:
              TEST: python
            lua:
              TEST: lua
        steps:
          - checkout: self
            fetchDepth: 20
          - template: extra/azure-pipelines/install-neko-snapshot.yaml
            parameters:
              platform: linux64
          - task: DownloadPipelineArtifact@0
            inputs:
              artifactName: 'linuxBinaries'
              targetPath: linuxBinaries
          - script: |
              set -ex
              tar -xf linuxBinaries/*_bin.tar.gz -C linuxBinaries --strip-components=1
              sudo mkdir -p /usr/local/bin/
              sudo mkdir -p /usr/local/share/haxe/
              sudo ln -s `pwd`/linuxBinaries/haxe /usr/local/bin/haxe
              sudo ln -s `pwd`/linuxBinaries/haxelib /usr/local/bin/haxelib
              sudo ln -s `pwd`/linuxBinaries/std /usr/local/share/haxe/std
            displayName: Setup Haxe
          - script: haxe -version
            displayName: Print Haxe version
          - script: |
              set -ex
              mkdir ~/haxelib
              haxelib setup ~/haxelib
            displayName: Setup haxelib
          - script: |
              set -ex
              sudo apt update -qqy
              sudo apt install -qqy $APT_PACKAGES
            condition: and(succeeded(), variables['APT_PACKAGES'])
            displayName: Install apt packages
          - script: haxe RunCi.hxml
            workingDirectory: $(Build.SourcesDirectory)/tests
            env:
              ${{ if variables['SAUCE_ACCESS_KEY'] }}:
                SAUCE_ACCESS_KEY: $(SAUCE_ACCESS_KEY)
            displayName: Test

      - job: TestMac
        dependsOn: BuildMac
        pool:
          vmImage: 'macOS-10.13'
        strategy:
          matrix:
            macro:
              TEST: macro
            neko:
              TEST: neko
            hl:
              TEST: hl
              BREW_PACKAGES: ninja
            cpp:
              TEST: cpp
              HXCPP_COMPILE_CACHE: ~/hxcache
            java:
              TEST: java,jvm
            cs:
              TEST: cs
            js:
              TEST: js
            php:
              TEST: php
            flash:
              TEST: flash9,as3
            python:
              TEST: python
            lua:
              TEST: lua
        steps:
          - checkout: self
            fetchDepth: 20
          - template: extra/azure-pipelines/install-neko-snapshot.yaml
            parameters:
              platform: mac
          - task: DownloadPipelineArtifact@0
            inputs:
              artifactName: 'macBinaries'
              targetPath: macBinaries
          - script: |
              set -ex
              tar -xf macBinaries/*_bin.tar.gz -C macBinaries --strip-components=1
              sudo mkdir -p /usr/local/bin/
              sudo mkdir -p /usr/local/share/haxe/
              sudo ln -s `pwd`/macBinaries/haxe /usr/local/bin/haxe
              sudo ln -s `pwd`/macBinaries/haxelib /usr/local/bin/haxelib
              sudo ln -s `pwd`/macBinaries/std /usr/local/share/haxe/std
            displayName: Setup Haxe
          - script: haxe -version
            displayName: Print Haxe version
          - script: |
              set -ex
              mkdir ~/haxelib
              haxelib setup ~/haxelib
            displayName: Setup haxelib
          - script: brew install $BREW_PACKAGES
            condition: and(succeeded(), variables['BREW_PACKAGES'])
            displayName: Install homebrew packages
          - script: haxe RunCi.hxml
            workingDirectory: $(Build.SourcesDirectory)/tests
            displayName: Test

      - job: TestWin64
        dependsOn: BuildWin64
        pool:
          vmImage: 'windows-2019'
        variables:
          HAXELIB_ROOT: C:/haxelib
          HAXE_ARCH: 64
        strategy:
          matrix:
            macro:
              TEST: macro
            neko:
              TEST: neko
            hl:
              TEST: hl
            cpp:
              TEST: cpp
              HXCPP_COMPILE_CACHE: C:/hxcache
            java:
              TEST: java,jvm
            cs:
              TEST: cs
            js:
              TEST: js
            # https://github.com/microsoft/azure-pipelines-image-generation/issues/990
            # php:
            #   TEST: php
            # TODO. flash has never been enabled on our AppVeyor builds.
            # flash:
            #   TEST: flash9,as3
            python:
              TEST: python
            # TODO. Lua has never been enabled on our AppVeyor builds.
            # lua:
            #   TEST: lua
        steps:
          - checkout: self
            fetchDepth: 20
          - template: extra/azure-pipelines/install-neko-snapshot.yaml
            parameters:
              platform: windows64
          - task: DownloadPipelineArtifact@0
            inputs:
              artifactName: 'win64Binaries'
              targetPath: win64Binaries
          - powershell: |
              Set-PSDebug -Trace 1
              7z x win64Binaries/*_bin.zip -owin64Binaries
              $dir = Get-ChildItem win64Binaries/* -Name -Directory
              Rename-Item win64Binaries/$dir haxe
              $dir = '' + ( get-location ) + '\win64Binaries\haxe'
              dir $dir
              Set-PSDebug -Trace 0
              Write-Host "##vso[task.prependpath]$dir"
            displayName: Setup Haxe
          - script: haxe -version
            displayName: Print Haxe version
          - task: UsePythonVersion@0
            inputs:
              versionSpec: '3.7'
          - powershell: |
              Set-PSDebug -Trace 1
              $pypath = python -c "import sys; print(sys.executable)"
              $py3path = $pypath.replace("python.exe","python3.exe")
              cmd /c mklink $py3path $pypath
              python3 -V
            displayName: "Make Python 3 be available as python3 in the cmdline"
          - script: |
              mkdir "$(HAXELIB_ROOT)"
              haxelib setup "$(HAXELIB_ROOT)"
            displayName: Setup haxelib
          - script: haxe RunCi.hxml
            workingDirectory: $(Build.SourcesDirectory)/tests
            displayName: Test
  - stage: StageDeploy
    condition: and(succeeded(), not(variables['System.PullRequest.PullRequestId']))
    jobs:
      - job: S3
        condition: and(succeeded(), variables['HXBUILDS_AWS_ACCESS_KEY_ID'], variables['HXBUILDS_S3ADDR'])
        pool:
          vmImage: 'ubuntu-16.04'
        steps:
          - checkout: self
            fetchDepth: 20
          - task: DownloadPipelineArtifact@0
            inputs:
              artifactName: 'linuxBinaries'
              targetPath: linuxBinaries
            displayName: Download linuxBinaries
          - task: DownloadPipelineArtifact@0
            inputs:
              artifactName: 'macBinaries'
              targetPath: macBinaries
            displayName: Download macBinaries
          - task: DownloadPipelineArtifact@0
            inputs:
              artifactName: 'win64Binaries'
              targetPath: win64Binaries
            displayName: Download win64Binaries
          - task: DownloadPipelineArtifact@0
            inputs:
              artifactName: 'win32Binaries'
              targetPath: win32Binaries
            displayName: Download win32Binaries
          - template: extra/azure-pipelines/install-neko-snapshot.yaml
            parameters:
              platform: linux64
          - script: |
              set -ex
              tar -xf linuxBinaries/*_bin.tar.gz -C linuxBinaries --strip-components=1
              sudo mkdir -p /usr/local/bin/
              sudo mkdir -p /usr/local/share/haxe/
              sudo ln -s `pwd`/linuxBinaries/haxe /usr/local/bin/haxe
              sudo ln -s `pwd`/linuxBinaries/haxelib /usr/local/bin/haxelib
              sudo ln -s `pwd`/linuxBinaries/std /usr/local/share/haxe/std
            displayName: Setup Haxe
          - script: |
              set -ex
              sudo apt-get update -qqy
              sudo apt-get install -qqy awscli
            displayName: "Install awscli"
          - script: |
              set -ex
              COMMIT_HASH=`git rev-parse HEAD`
              COMMIT_HASH_SHORT=${COMMIT_HASH:0:7}
              COMMIT_DATE=`TZ=UTC git show --quiet --date='format-local:%Y-%m-%d' --format="%cd"`
              FILE_NAME=haxe_${COMMIT_DATE}_$(Build.SourceBranchName)_${COMMIT_HASH_SHORT}
              aws s3 cp linuxBinaries/*_bin.tar.gz      $(HXBUILDS_S3ADDR)/haxe/linux64/${FILE_NAME}.tar.gz
              aws s3 cp macBinaries/*_bin.tar.gz        $(HXBUILDS_S3ADDR)/haxe/mac/${FILE_NAME}.tar.gz
              aws s3 cp win64Binaries/*_bin.zip         $(HXBUILDS_S3ADDR)/haxe/windows64/${FILE_NAME}.zip
              aws s3 cp win64Binaries/*_installer.zip   $(HXBUILDS_S3ADDR)/haxe/windows64-installer/${FILE_NAME}.zip
              aws s3 cp win64Binaries/*.nupkg           $(HXBUILDS_S3ADDR)/haxe/windows64-choco/
              aws s3 cp win32Binaries/*_bin.zip         $(HXBUILDS_S3ADDR)/haxe/windows/${FILE_NAME}.zip
              aws s3 cp win32Binaries/*_installer.zip   $(HXBUILDS_S3ADDR)/haxe/windows-installer/${FILE_NAME}.zip
              aws s3 cp win32Binaries/*.nupkg           $(HXBUILDS_S3ADDR)/haxe/windows-choco/
            env:
              AWS_ACCESS_KEY_ID: $(HXBUILDS_AWS_ACCESS_KEY_ID)
              AWS_SECRET_ACCESS_KEY: $(HXBUILDS_AWS_SECRET_ACCESS_KEY)
            displayName: Upload binaries
          - script: |
              set -ex
              aws s3 cp linuxBinaries/*_bin.tar.gz      $(HXBUILDS_S3ADDR)/haxe/linux64/haxe_latest.tar.gz
              aws s3 cp macBinaries/*_bin.tar.gz        $(HXBUILDS_S3ADDR)/haxe/mac/haxe_latest.tar.gz
              aws s3 cp win64Binaries/*_bin.zip         $(HXBUILDS_S3ADDR)/haxe/windows64/haxe_latest.zip
              aws s3 cp win64Binaries/*_installer.zip   $(HXBUILDS_S3ADDR)/haxe/windows64-installer/haxe_latest.zip
              aws s3 cp win32Binaries/*_bin.zip         $(HXBUILDS_S3ADDR)/haxe/windows/haxe_latest.zip
              aws s3 cp win32Binaries/*_installer.zip   $(HXBUILDS_S3ADDR)/haxe/windows-installer/haxe_latest.zip

              # Chocolatey packages have to be named with version number,
              # so let's use web redirection to keep the original file name.
              [[ "$HXBUILDS_S3ADDR" =~ s3://([^/]+)(.*) ]] && HXBUILDS_S3BUCKET="${BASH_REMATCH[1]}" && HXBUILDS_S3PATH="${BASH_REMATCH[2]}"
              [[ `echo win64Binaries/*.nupkg` =~ win64Binaries/(.+) ]] && FILE_NAME="${BASH_REMATCH[1]}"
              aws s3 cp $(HXBUILDS_S3ADDR)/haxe/windows64-choco/${FILE_NAME} $(HXBUILDS_S3ADDR)/haxe/windows64-choco/haxe_latest.nupkg --acl public-read --website-redirect "${HXBUILDS_S3PATH}/haxe/windows64-choco/${FILE_NAME}"
              [[ `echo win32Binaries/*.nupkg` =~ win32Binaries/(.+) ]] && FILE_NAME="${BASH_REMATCH[1]}"
              aws s3 cp $(HXBUILDS_S3ADDR)/haxe/windows-choco/${FILE_NAME}   $(HXBUILDS_S3ADDR)/haxe/windows-choco/haxe_latest.nupkg   --acl public-read --website-redirect "${HXBUILDS_S3PATH}/haxe/windows-choco/${FILE_NAME}"
            env:
              AWS_ACCESS_KEY_ID: $(HXBUILDS_AWS_ACCESS_KEY_ID)
              AWS_SECRET_ACCESS_KEY: $(HXBUILDS_AWS_SECRET_ACCESS_KEY)
            condition: and(succeeded(), eq(variables['Build.SourceBranchName'], 'development'))
            displayName: Update "latest"
          - script: |
              set -ex
              haxe --run runci.Indexer $(HXBUILDS_S3ADDR)/haxe/linux64
              aws s3 cp index.html     $(HXBUILDS_S3ADDR)/haxe/linux64/
              haxe --run runci.Indexer $(HXBUILDS_S3ADDR)/haxe/mac
              aws s3 cp index.html     $(HXBUILDS_S3ADDR)/haxe/mac/
              haxe --run runci.Indexer $(HXBUILDS_S3ADDR)/haxe/windows64
              aws s3 cp index.html     $(HXBUILDS_S3ADDR)/haxe/windows64/
              haxe --run runci.Indexer $(HXBUILDS_S3ADDR)/haxe/windows64-installer
              aws s3 cp index.html     $(HXBUILDS_S3ADDR)/haxe/windows64-installer/
              haxe --run runci.Indexer $(HXBUILDS_S3ADDR)/haxe/windows64-choco
              aws s3 cp index.html     $(HXBUILDS_S3ADDR)/haxe/windows64-choco/
              haxe --run runci.Indexer $(HXBUILDS_S3ADDR)/haxe/windows
              aws s3 cp index.html     $(HXBUILDS_S3ADDR)/haxe/windows/
              haxe --run runci.Indexer $(HXBUILDS_S3ADDR)/haxe/windows-installer
              aws s3 cp index.html     $(HXBUILDS_S3ADDR)/haxe/windows-installer/
              haxe --run runci.Indexer $(HXBUILDS_S3ADDR)/haxe/windows-choco
              aws s3 cp index.html     $(HXBUILDS_S3ADDR)/haxe/windows-choco/
              haxe --run runci.Indexer $(HXBUILDS_S3ADDR)/haxe
              aws s3 cp index.html     $(HXBUILDS_S3ADDR)/haxe/
            workingDirectory: $(Build.SourcesDirectory)/tests
            env:
              AWS_ACCESS_KEY_ID: $(HXBUILDS_AWS_ACCESS_KEY_ID)
              AWS_SECRET_ACCESS_KEY: $(HXBUILDS_AWS_SECRET_ACCESS_KEY)
            displayName: Update indices
      - job: ApiHaxeOrg
        condition: and(succeeded(), variables['GHP_USERNAME'], variables['GHP_EMAIL'])
        pool:
          vmImage: 'ubuntu-16.04'
        steps:
          - checkout: none
          - template: extra/azure-pipelines/install-neko-snapshot.yaml
            parameters:
              platform: linux64
          - task: DownloadPipelineArtifact@0
            inputs:
              artifactName: 'linuxBinaries'
              targetPath: linuxBinaries
            displayName: Download linuxBinaries
          - script: |
              set -ex
              tar -xf linuxBinaries/*_bin.tar.gz -C linuxBinaries --strip-components=1
              sudo mkdir -p /usr/local/bin/
              sudo mkdir -p /usr/local/share/haxe/
              sudo ln -s `pwd`/linuxBinaries/haxe /usr/local/bin/haxe
              sudo ln -s `pwd`/linuxBinaries/haxelib /usr/local/bin/haxelib
              sudo ln -s `pwd`/linuxBinaries/std /usr/local/share/haxe/std
            displayName: Setup Haxe
          - task: DownloadPipelineArtifact@0
            inputs:
              artifactName: 'xmldoc'
              targetPath: xmldoc
            displayName: Download xmldoc
          - script: |
              set -ex
              LOCAL="`pwd`/extra/api.haxe.org"
              git clone "${GHP_REMOTE}" "${LOCAL}"
              haxe --cwd "${LOCAL}" --run ImportXml "`pwd`/xmldoc"
            env:
              GHP_REMOTE: $(GHP_REMOTE)
            displayName: Deploy to api.haxe.org